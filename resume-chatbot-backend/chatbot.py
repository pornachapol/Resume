# resume-chatbot-backend/chatbot.py
import os, re, time, io
from typing import List, Tuple, Optional, Dict

import httpx
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import google.generativeai as genai
import fitz  # PyMuPDF
import numpy as np

# ===================== ENV =====================
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
RESUME_URL = os.getenv("RESUME_URL")  # e.g. https://raw.githubusercontent.com/<user>/<repo>/main/assets/Resume.pdf
ALLOWED_ORIGINS = [o.strip() for o in (os.getenv("ALLOWED_ORIGINS", "")).split(",") if o.strip()]
MODEL_NAME = os.getenv("MODEL_NAME", "gemini-2.0-flash")
ALLOW_OPINION = (os.getenv("ALLOW_OPINION", "false").lower() == "true")


if not GOOGLE_API_KEY:
    print("WARNING: GOOGLE_API_KEY not set")

genai.configure(api_key=GOOGLE_API_KEY)

# ===================== APP =====================
app = FastAPI(title="Resume-only Chatbot")
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS or ["*"],  # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö; ‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏î‡πÄ‡∏°‡∏ô
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===================== Schemas =====================
class ChatRequest(BaseModel):
    message: str

class ChatResponse(BaseModel):
    reply: str
    sources: List[Tuple[int, str]] = []

# ===================== In-memory store =====================
CHUNKS: List[str] = []
VECTORIZER = None
MATRIX = None
LAST_FETCH_AT = 0

# ===================== Helpers =====================
# ===== Helpers needed by /chat =====
from typing import Optional

# ‡πÇ‡∏Ñ‡∏£‡∏á PROFILE ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô KeyError)
PROFILE = {
    "name": None,
    "name_th": None,
    "contacts": {"email": None, "phone": None, "location": None, "links": []},
    "skills": [],
    "experience": [],
    "education": [],
    "etc": []
}

def is_summary_query(q: str) -> bool:
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß '‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°' / 'overview'
    """
    ql = (q or "").lower()
    keys = [
        "‡∏™‡∏£‡∏∏‡∏õ", "‡πÄ‡∏•‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°", "overview", "summary",
        "‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°", "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß", "‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°", "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥", "‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà", "‡∏¢‡πà‡∏≠", "profile"
    ]
    return any(k in ql for k in keys)

def opinion_footer() -> str:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á footer ‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å PROFILE ‡∏à‡∏£‡∏¥‡∏á
    """
    c = PROFILE.get("contacts", {}) if isinstance(PROFILE, dict) else {}
    parts = []
    if c.get("email"):
        parts.append(f"‡∏≠‡∏µ‡πÄ‡∏°‡∏•: {c['email']}")
    if c.get("phone"):
        parts.append(f"‡πÇ‡∏ó‡∏£: {c['phone']}")
    tail = "üí° ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á"
    if parts:
        tail += " ‚Äî " + " | ".join(parts)
    return tail

def answer_from_profile(q: str) -> Optional[str]:
    """
    ‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å PROFILE ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•)
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ó‡∏¢/‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    """
    ql = (q or "").strip().lower()
    ql_nospace = ql.replace(" ", "")

    c = PROFILE.get("contacts", {}) if isinstance(PROFILE, dict) else {}
    skills = PROFILE.get("skills") or []
    exp = PROFILE.get("experience") or []
    edu = PROFILE.get("education") or []
    links = c.get("links") or []

    def find_link(domain_keyword: str) -> Optional[str]:
        for u in links:
            if domain_keyword in (u or "").lower():
                return u
        return None

    # ‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏Å‡πà‡∏≠‡∏ô
    if any(k in ql for k in ["‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢", "‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ó‡∏¢", "thai name", "thai fullname"]):
        if PROFILE.get("name_th"):
            return f"‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢: {PROFILE['name_th']}"
        if PROFILE.get("name"):
            return f"‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•: {PROFILE['name']}"

    # ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    if any(k in ql for k in ["‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏£‡∏¥‡∏á", "‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•", "‡∏ä‡∏∑‡πà‡∏≠", "full name", "your name", "name", "name?"]) \
       or "‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£" in ql_nospace:
        if PROFILE.get("name"):
            if PROFILE.get("name_th"):
                return f"‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•: {PROFILE['name']} (TH: {PROFILE['name_th']})"
            return f"‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•: {PROFILE['name']}"

    # Contact ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏¥‡∏•‡∏î‡πå
    if any(k in ql for k in ["email", "‡∏≠‡∏µ‡πÄ‡∏°‡∏•", "‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå"]):
        if c.get("email"): return f"‡∏≠‡∏µ‡πÄ‡∏°‡∏•: {c['email']}"
    if any(k in ql for k in ["phone", "‡πÇ‡∏ó‡∏£", "‡πÄ‡∏ö‡∏≠‡∏£‡πå", "‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£", "‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå"]):
        if c.get("phone"): return f"‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£: {c['phone']}"
    if any(k in ql for k in ["location", "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà", "‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏∞‡πÑ‡∏£"]):
        if c.get("location"): return f"‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á: {c['location']}"
    if "linkedin" in ql:
        li = find_link("linkedin")
        if li: return f"LinkedIn: {li}"
    if "github" in ql:
        gh = find_link("github")
        if gh: return f"GitHub: {gh}"

    # Contact ‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏°
    if any(k in ql for k in ["‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠", "contact", "‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠", "‡∏Ñ‡∏≠‡∏ô‡πÅ‡∏ó‡∏Ñ"]):
        parts = []
        if c.get("email"): parts.append(f"‡∏≠‡∏µ‡πÄ‡∏°‡∏•: {c['email']}")
        if c.get("phone"): parts.append(f"‡πÇ‡∏ó‡∏£: {c['phone']}")
        if c.get("location"): parts.append(f"‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á: {c['location']}")
        li = find_link("linkedin")
        gh = find_link("github")
        if li: parts.append(f"LinkedIn: {li}")
        if gh: parts.append(f"GitHub: {gh}")
        if parts: return " | ".join(parts)

    # Skills
    if any(k in ql for k in ["‡∏ó‡∏±‡∏Å‡∏©‡∏∞", "skills", "skill", "‡∏™‡∏Å‡∏¥‡∏•"]):
        if skills:
            if any(k in ql for k in ["‡∏´‡∏•‡∏±‡∏Å", "top", "‡πÄ‡∏î‡πà‡∏ô", "core"]):
                return "‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏´‡∏•‡∏±‡∏Å: " + ", ".join(skills[:10])
            return "‡∏ó‡∏±‡∏Å‡∏©‡∏∞: " + ", ".join(skills[:30])

    # Experience
    if any(k in ql for k in ["‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå", "experience", "‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô", "‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤"]):
        if exp:
            return "‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏™‡∏£‡∏∏‡∏õ):\n- " + "\n- ".join(exp[:8])

    # Education
    if any(k in ql for k in ["‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "education", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡∏à‡∏ö‡∏à‡∏≤‡∏Å", "‡∏ß‡∏∏‡∏í‡∏¥‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤"]):
        if edu:
            return "‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤:\n- " + "\n- ".join(edu[:8])

    return None

# ====== Opinion / Summary helpers ======
def ask_opinion(question: str) -> str:
    """
    ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å PDF ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡πÅ‡∏•‡∏∞ ALLOW_OPINION=true
    ‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏≠‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
    """
    model = genai.GenerativeModel(MODEL_NAME)
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ï‡∏≠‡∏ö '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion)' ‡∏ï‡πà‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ
‡∏Å‡∏ï‡∏¥‡∏Å‡∏≤:
- ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠/‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£/‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà/‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
- ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥/‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠ ‡πÜ ‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢ "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion):"

[‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°]
{question}
"""
    try:
        resp = model.generate_content(prompt)
        ans = (getattr(resp, "text", "") or "").strip()
        return ans or "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion): ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ PDF ‡∏à‡∏∂‡∏á‡∏Ç‡∏≠‡∏ï‡∏≠‡∏ö‡πÄ‡∏ä‡∏¥‡∏á‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ"
    except Exception as e:
        print(f"[ask_opinion] error: {e}")
        return "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion): ‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏à‡∏∂‡∏á‡∏ï‡∏≠‡∏ö‡πÄ‡∏ä‡∏¥‡∏á‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ"

def summarize_all_chunks(chunks: List[str]) -> str:
    """
    ‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏ö‡∏ö map-reduce:
    - ‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‚Üí ‡∏™‡πà‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö'
    - ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‚Üí ‡∏ñ‡πâ‡∏≤ ALLOW_OPINION true ‚Üí ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion)
    """
    if not chunks:
        if ALLOW_OPINION:
            return ask_opinion("‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå/‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ") + "\n\n" + opinion_footer()
        return "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

    model = genai.GenerativeModel(MODEL_NAME)

    partials = []
    for c in chunks[:8]:
        try:
            r = model.generate_content(
                "‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≤‡∏£‡∏∞‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô bullet ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏±‡πâ‡∏ô ‡πÜ "
                "‡πÇ‡∏î‡∏¢‡∏´‡πâ‡∏≤‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö' ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô:\n\n" + c
            )
            partials.append((r.text or "").strip())
        except Exception as e:
            print(f"[summarize] chunk error: {e}")

    joined = "\n".join([p for p in partials if p])
    if not joined:
        if ALLOW_OPINION:
            return ask_opinion("‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå/‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ") + "\n\n" + opinion_footer()
        return "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

    try:
        r2 = model.generate_content(
            "‡∏£‡∏ß‡∏°‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ "
            "‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÄ‡∏ä‡πà‡∏ô '‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö':\n\n" + joined
        )
        final_sum = (r2.text or "").strip()

        # cleanup prefix ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ú‡∏•‡∏≠‡πÉ‡∏™‡πà‡∏°‡∏≤
        if final_sum:
            bad_prefixes = [
                "‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö:", "‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö",
                "‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö:", "‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"
            ]
            fs_lower = final_sum.lower().lstrip()
            for bp in bad_prefixes:
                if fs_lower.startswith(bp):
                    cut_len = len(final_sum) - len(fs_lower)
                    final_sum = final_sum[cut_len + len(bp):].lstrip(": \n-")
                    break

        if not final_sum:
            if ALLOW_OPINION:
                return ask_opinion("‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå/‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ") + "\n\n" + opinion_footer()
            return "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

        return final_sum

    except Exception as e:
        print(f"[summarize reduce] error: {e}")
        if ALLOW_OPINION:
            return ask_opinion("‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå/‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ") + "\n\n" + opinion_footer()
        return "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

def clean(txt: str) -> str:
    return re.sub(r"\s+", " ", txt or "").strip()

def html_to_text(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    for t in soup(["script", "style", "noscript"]):
        t.decompose()
    return clean(soup.get_text(" "))

def chunk_text(text: str, size=1800, overlap=350) -> List[str]:
    blocks = smart_split(text)   # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô
    chunks = []
    for blk in blocks:
        i = 0
        while i < len(blk):
            chunks.append(blk[i:i+size])
            i += max(1, size - overlap)
    return chunks

def embed_texts(texts: List[str]) -> np.ndarray:
    """
    ‡πÉ‡∏ä‡πâ Google AI Studio: text-embedding-004
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô np.ndarray shape (N, D)
    """
    if not texts:
        return np.zeros((0, 1))
    try:
        resp = genai.embed_content(
            model="text-embedding-004",
            content=texts,
            task_type="retrieval_document"  # ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏á‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
        )
        # resp["embedding"] ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á 1 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ / resp["embeddings"] ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (SDK ‡∏≠‡∏≤‡∏à‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô)
        embs = resp.get("embeddings") or resp.get("embedding")
        if isinstance(embs, list) and isinstance(embs[0], dict) and "values" in embs[0]:
            vecs = np.array([e["values"] for e in embs], dtype="float32")
        elif isinstance(embs, dict) and "values" in embs:
            vecs = np.array([embs["values"]], dtype="float32")
        else:
            # ‡∏ö‡∏≤‡∏á SDK: resp ‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á float[]
            vecs = np.array(embs, dtype="float32")
        # ‡∏õ‡∏Å‡∏ï‡∏¥ vectorize ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
        return vecs
    except Exception as e:
        print(f"[embed_texts] error: {e}")
        return np.zeros((len(texts), 1), dtype="float32")

EMB_MATRIX = None  # np.ndarray (num_chunks, dim)

async def fetch_resume_text() -> str:
    """
    ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å RESUME_URL
    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô PDF: ‡πÉ‡∏ä‡πâ PyMuPDF (fitz) ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡πÅ‡∏°‡πà‡∏ô‡∏Å‡∏±‡∏ö‡πÄ‡∏•‡∏¢‡πå‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡πÅ‡∏ô‡πà‡∏ô ‡πÜ)
    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô HTML: ‡πÉ‡∏ä‡πâ BeautifulSoup
    """
    if not RESUME_URL:
        return ""
    headers = {"User-Agent": "resume-bot/1.0 (+https://render.com)"}
    try:
        async with httpx.AsyncClient(timeout=60) as client:
            r = await client.get(RESUME_URL, follow_redirects=True, headers=headers)
            r.raise_for_status()
            content_type = (r.headers.get("Content-Type") or "").lower()

            if "application/pdf" in content_type or RESUME_URL.lower().endswith(".pdf"):
                # ‡∏≠‡πà‡∏≤‡∏ô PDF ‡∏î‡πâ‡∏ß‡∏¢ PyMuPDF
                doc = fitz.open(stream=r.content, filetype="pdf")
                pages = []
                for p in doc:
                    # ‡πÉ‡∏ä‡πâ textpage.extractTEXT() ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏° layout ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ get_text("text")
                    tp = p.get_textpage()
                    txt = tp.extractTEXT() or ""
                    if txt.strip():
                        pages.append(txt)
                return clean("\n".join(pages))

            # HTML
            return html_to_text(r.text)
    except Exception as e:
        print(f"[fetch_resume_text] error: {e}")
        return ""

SECTION_HINTS = [
    # Experience / Career
    r"\b(PROFESSIONAL EXPERIENCE|EXPERIENCE|WORK EXPERIENCE|CAREER HISTORY|EMPLOYMENT HISTORY|WORK HISTORY|PROFESSIONAL BACKGROUND)\b",

    # Education / Certifications
    r"\b(EDUCATION|ACADEMIC BACKGROUND|QUALIFICATIONS|CERTIFICATION|CERTIFICATIONS|TRAINING|COURSES|CREDENTIALS)\b",

    # Achievements / Awards
    r"\b(KEY ACHIEVEMENTS|ACHIEVEMENTS|AWARDS|HONORS|DISTINCTIONS|RECOGNITION|MILESTONES|ACCOMPLISHMENTS)\b",

    # Skills / Expertise
    r"\b(AREA OF EXPERTISE|SKILLS?|TECHNICAL SKILLS|CORE COMPETENCIES|EXPERTISE|SPECIALTIES|CAPABILITIES|PROFICIENCIES|KNOWLEDGE AREAS)\b",

    # Languages & Additional Info
    r"\b(ADDITIONAL INFORMATION|LANGUAGES?|HOBBIES|INTERESTS|PERSONAL DETAILS|CONTACT INFORMATION|PROFILE|SUMMARY|OVERVIEW)\b",

    # Projects
    r"\b(PROJECTS|KEY PROJECTS|SELECTED PROJECTS|PROJECT EXPERIENCE|CASE STUDIES)\b",

    # Objectives / Goals
    r"\b(CAREER OBJECTIVE|OBJECTIVES|GOAL|FUTURE GOALS|PROFESSIONAL GOALS|MISSION|VISION|PASSION)\b",

    # Strengths / Weaknesses / Self
    r"\b(STRENGTHS|WEAKNESSES|AREAS FOR IMPROVEMENT|PERSONAL ATTRIBUTES|CHARACTERISTICS|VALUES)\b",

    # Frameworks / Methods
    r"\b(METHODOLOGIES|FRAMEWORKS|TOOLS|PROCESS IMPROVEMENT|LEAN SIX SIGMA|PRA|SWOT|FISHBONE|IPSO|PDCA)\b",
]

def smart_split(text: str) -> List[str]:
    # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÉ‡∏´‡∏ç‡πà ‡πÜ
    if not text:
        return []
    lines = text.splitlines()
    blocks, cur = [], []
    import re as _re
    for ln in lines:
        if any(_re.search(pat, ln.strip(), flags=_re.IGNORECASE) for pat in SECTION_HINTS):
            if cur:
                blocks.append("\n".join(cur).strip())
                cur = []
        cur.append(ln)
    if cur:
        blocks.append("\n".join(cur).strip())
    # ‡∏ñ‡πâ‡∏≤ detect ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏Å‡πá‡∏Ñ‡∏∑‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏Å‡πâ‡∏≠‡∏ô
    return [b for b in blocks if b] or [text]
    
def parse_profile(full_text: str):
    """
    ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô PROFILE dict:
    - name / contacts(email/phone/location/links)
    - skills / experience / education / etc
    """
    global PROFILE
    text = full_text or ""
    lines = [l.strip() for l in text.splitlines() if l.strip()]

    # --- Name heuristic (‡∏î‡∏π‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ï‡πâ‡∏ô ‡πÜ) ---
    name = None
    for line in lines[:30]:
        ws = line.split()
        if 2 <= len(ws) <= 4 and all(w[:1].isupper() for w in ws if w.isalpha()):
            name = line
            break

    # --- Contacts ---
    email = None
    phone = None
    location = None
    links: List[str] = []

    m = re.search(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}", text)
    if m: email = m.group(0)

    m = re.search(r"(\+?\d[\d \-]{7,}\d)", text)
    if m: phone = m.group(1)

    m = re.search(r"(Bangkok|Thailand|Address\s*:\s*.+|Location\s*:\s*.+)", text, flags=re.IGNORECASE)
    if m: location = m.group(0)

    links = re.findall(r"https?://\S+", text)

    # --- Section grouping (‡∏´‡∏¢‡∏≤‡∏ö) ---
    blocks = {"skills": [], "experience": [], "education": [], "etc": []}
    current = None
    for line in lines:
        low = line.lower()
        if re.match(r"skills\b", low) or "skills &" in low:
            current = "skills"; continue
        if "experience" in low or "professional experience" in low:
            current = "experience"; continue
        if "education" in low or "certification" in low:
            current = "education"; continue
        if current is None:
            current = "etc"
        blocks[current].append(line)

    # skills ‚Üí list
    skills: List[str] = []
    if blocks["skills"]:
        joined = " ".join(blocks["skills"])
        parts = re.split(r"[‚Ä¢\u2022,;|/]", joined)
        for p in parts:
            s = p.strip()
            if 1 < len(s) <= 40:
                skills.append(s)
        # uniq
        skills = list(dict.fromkeys(skills))

    PROFILE = {
        "name": name,
        "contacts": {
            "email": email,
            "phone": phone,
            "location": location,
            "links": links[:6],
        },
        "skills": skills,
        "experience": blocks["experience"][:80],
        "education": blocks["education"][:40],
        "etc": blocks["etc"][:40]
    }

def build_index(chunks: List[str]):
    global VECTORIZER, MATRIX, EMB_MATRIX
    VECTORIZER = TfidfVectorizer(min_df=1, ngram_range=(1,2))
    MATRIX = VECTORIZER.fit_transform(chunks)
    EMB_MATRIX = embed_texts(chunks)  # <- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ù‡∏±‡πà‡∏á‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå
    # L2 normalize ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Ñ‡∏≠‡∏™‡πÑ‡∏ã‡∏ô‡πå
    if EMB_MATRIX is not None and EMB_MATRIX.size > 0:
        norms = np.linalg.norm(EMB_MATRIX, axis=1, keepdims=True) + 1e-12
        EMB_MATRIX = EMB_MATRIX / norms


async def ensure_index(force=False):
    global CHUNKS, LAST_FETCH_AT, PROFILE
    if CHUNKS and not force and (time.time() - LAST_FETCH_AT < 3600):
        return
    text = await fetch_resume_text()
    parse_profile(text)
    CHUNKS = chunk_text(text) if text else []
    if CHUNKS:
        build_index(CHUNKS)
    LAST_FETCH_AT = time.time()

def normalize_query(q: str) -> str:
    ql = q.lower()
    mapping = {
        "‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡πá‡∏°": "full name",
        "‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏£‡∏¥‡∏á": "first name",
        "‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•": "surname",
        "‡∏ä‡∏∑‡πà‡∏≠": "name",
        "what is your name": "full name",
        "your name": "full name",
        "name?": "name",
        "‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠": "contact",
    }
    for k, v in mapping.items():
        ql = ql.replace(k, v)
    return ql

def retrieve_hybrid(q: str, k=5, alpha=0.6):
    """
    alpha: ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á embedding (semantic)
    (1-alpha): ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å TF-IDF (keyword)
    """
    if not CHUNKS or VECTORIZER is None:
        return []
    # TF-IDF
    qv = VECTORIZER.transform([q])
    sims_tfidf = cosine_similarity(qv, MATRIX).ravel()

    # Embedding
    emb_q = embed_texts([q])
    if emb_q is not None and emb_q.size > 0 and EMB_MATRIX is not None and EMB_MATRIX.size > 0:
        qn = emb_q / (np.linalg.norm(emb_q, axis=1, keepdims=True) + 1e-12)
        sims_vec = (EMB_MATRIX @ qn.T).ravel()
    else:
        sims_vec = np.zeros_like(sims_tfidf)

    # Normalize ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ù‡∏±‡πà‡∏á
    def norm(x):
        x = x - x.min()
        m = x.max() or 1.0
        return x / m
    s1 = norm(sims_tfidf)
    s2 = norm(sims_vec)

    hybrid = alpha * s2 + (1 - alpha) * s1
    order = np.argsort(hybrid)[::-1][:k]
    return [(int(i), CHUNKS[int(i)], float(hybrid[int(i)])) for i in order if hybrid[int(i)] > 0.01]


def try_extract_name_heuristic(full_text: str) -> Optional[str]:
    if not full_text:
        return None
    head = full_text[:2000]
    lines = [l.strip() for l in head.split("\n") if l.strip()]
    candidates = []
    for line in lines[:40]:
        words = line.split()
        if 2 <= len(words) <= 4 and all(w[0:1].isupper() for w in words if w.isalpha()):
            candidates.append(line)
    if not candidates:
        for idx, line in enumerate(lines[:50]):
            if "resume" in line.lower() and idx > 0:
                candidates.append(lines[idx-1])
    return max(candidates, key=len) if candidates else None



    # -------- Name (TH/EN) --------
    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏£‡∏∞‡∏ö‡∏∏ "‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢" / "‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ó‡∏¢" ‡∏Å‡πà‡∏≠‡∏ô
    if any(k in ql for k in ["‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢", "‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ó‡∏¢", "thai name", "thai fullname"]):
        if PROFILE.get("name_th"):
            return f"‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢: {PROFILE['name_th']}"
        # ‡πÑ‡∏°‡πà‡∏°‡∏µ name_th ‡∏Å‡πá fallback ‡πÄ‡∏õ‡πá‡∏ô EN
        if PROFILE.get("name"):
            return f"‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•: {PROFILE['name']}"

    # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠
    if any(k in ql for k in [
        "‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏£‡∏¥‡∏á", "‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•", "‡∏ä‡∏∑‡πà‡∏≠", 
        "full name", "your name", "name", "name?"
    ]) or "‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£" in ql_nospace:
        if PROFILE.get("name"):
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà
            if PROFILE.get("name_th"):
                return f"‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•: {PROFILE['name']} (TH: {PROFILE['name_th']})"
            return f"‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•: {PROFILE['name']}"

    # -------- Contacts (‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏≤‡∏°) --------
    # Email only
    if any(k in ql for k in ["email", "‡∏≠‡∏µ‡πÄ‡∏°‡∏•", "‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå"]):
        if c.get("email"):
            return f"‡∏≠‡∏µ‡πÄ‡∏°‡∏•: {c['email']}"

    # Phone only
    if any(k in ql for k in ["phone", "‡πÇ‡∏ó‡∏£", "‡πÄ‡∏ö‡∏≠‡∏£‡πå", "‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£", "‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå"]):
        if c.get("phone"):
            return f"‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£: {c['phone']}"

    # Location only
    if any(k in ql for k in ["location", "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà", "‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏∞‡πÑ‡∏£"]):
        if c.get("location"):
            return f"‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á: {c['location']}"

    # LinkedIn only
    if "linkedin" in ql:
        li = find_link("linkedin")
        if li:
            return f"LinkedIn: {li}"

    # GitHub only
    if "github" in ql:
        gh = find_link("github")
        if gh:
            return f"GitHub: {gh}"

    # Contact summary
    if any(k in ql for k in ["‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠", "contact", "‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠", "‡∏Ñ‡∏≠‡∏ô‡πÅ‡∏ó‡∏Ñ"]):
        parts = []
        if c.get("email"): parts.append(f"‡∏≠‡∏µ‡πÄ‡∏°‡∏•: {c['email']}")
        if c.get("phone"): parts.append(f"‡πÇ‡∏ó‡∏£: {c['phone']}")
        if c.get("location"): parts.append(f"‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á: {c['location']}")
        li = find_link("linkedin")
        gh = find_link("github")
        if li: parts.append(f"LinkedIn: {li}")
        if gh: parts.append(f"GitHub: {gh}")
        if parts:
            return " | ".join(parts)

    # -------- Skills --------
    if any(k in ql for k in ["‡∏ó‡∏±‡∏Å‡∏©‡∏∞", "skills", "skill", "‡∏™‡∏Å‡∏¥‡∏•"]):
        if skills:
            # ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ top/‡∏´‡∏•‡∏±‡∏Å ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏™‡∏±‡πâ‡∏ô ‡πÜ
            if any(k in ql for k in ["‡∏´‡∏•‡∏±‡∏Å", "top", "‡πÄ‡∏î‡πà‡∏ô", "core"]):
                return "‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏´‡∏•‡∏±‡∏Å: " + ", ".join(skills[:10])
            return "‡∏ó‡∏±‡∏Å‡∏©‡∏∞: " + ", ".join(skills[:30])

    # -------- Experience --------
    if any(k in ql for k in ["‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå", "experience", "‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô", "‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤"]):
        if exp:
            # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 8 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î ‡∏û‡∏≠‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
            return "‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏™‡∏£‡∏∏‡∏õ):\n- " + "\n- ".join(exp[:8])

    # -------- Education --------
    if any(k in ql for k in ["‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "education", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡∏à‡∏ö‡∏à‡∏≤‡∏Å", "‡∏ß‡∏∏‡∏í‡∏¥‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤"]):
        if edu:
            return "‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤:\n- " + "\n- ".join(edu[:8])

    return None

def ask_gemini(question: str, contexts: List[str]) -> str:
    """
    ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (PDF) ‡∏Å‡πà‡∏≠‡∏ô
    - ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí ‡∏ï‡∏≠‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ '‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å PDF:' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ‚Üí ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion): ...'
      ‡πÇ‡∏î‡∏¢‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠/‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç/‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
    """
    model = genai.GenerativeModel(MODEL_NAME)
    ctx = "\n\n---\n".join(contexts) if contexts else ""
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà (PDF) ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å

‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
- ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô [‡∏ö‡∏£‡∏¥‡∏ö‡∏ó] ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£
- ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó" ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion): ...'
  ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥/‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠-‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤-‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
- ‡∏´‡πâ‡∏≤‡∏°‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å PDF

‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:
- ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô PDF: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢ "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å PDF: ..."
- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô PDF: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢ "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion): ..."

[‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å PDF]
{ctx}

[‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°]
{question}

‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
"""
    try:
        resp = model.generate_content(prompt)
        ans = (getattr(resp, "text", "") or "").strip()
        # safety net: ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏á‡∏µ‡∏¢‡∏ö ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà opinion ‡∏ï‡∏≤‡∏° flag
        if not ans:
            return "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion): ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô PDF ‡∏à‡∏∂‡∏á‡∏Ç‡∏≠‡∏ï‡∏≠‡∏ö‡πÄ‡∏ä‡∏¥‡∏á‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á"
        return ans
    except Exception as e:
        print(f"[ask_gemini] error: {e}")
        return "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion): ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ‡∏à‡∏∂‡∏á‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á"

def opinion_footer() -> str:
    c = PROFILE.get("contacts", {}) if isinstance(PROFILE, dict) else {}
    email = c.get("email")
    phone = c.get("phone")
    tail = "üí° ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á"
    ways = []
    if email: ways.append(f"‡∏≠‡∏µ‡πÄ‡∏°‡∏•: {email}")
    if phone: ways.append(f"‡πÇ‡∏ó‡∏£: {phone}")
    if ways:
        tail += " ‚Äî " + " | ".join(ways)
    return tail


@app.get("/context")
async def get_context():
    await ensure_index()
    # ‡∏Ñ‡∏∑‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3 ‡∏ä‡∏¥‡πâ‡∏ô‡πÅ‡∏£‡∏Å‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏ä‡∏∑‡πà‡∏≠/‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏±‡∏ß ‡πÜ ‡∏°‡∏≤‡πÑ‡∏´‡∏°
    return {"count": len(CHUNKS), "sample": CHUNKS[:3]}

# ===================== Routes =====================
@app.get("/")
def home():
    return {"service": "resume-chatbot", "status": "ok", "docs": "/docs", "health": "/health"}

@app.get("/health")
def health():
    return {"ok": True}

@app.get("/debug")
async def debug():
    await ensure_index()
    return {
        "chunks": len(CHUNKS),
        "resume_url": RESUME_URL,
        "model": MODEL_NAME,
        "profile": {
            "name": PROFILE.get("name"),
            "contacts": PROFILE.get("contacts"),
            "skills_count": len(PROFILE.get("skills", [])),
            "experience_items": len(PROFILE.get("experience", [])),
            "education_items": len(PROFILE.get("education", [])),
        }
    }

@app.get("/refresh")
async def refresh():
    await ensure_index(force=True)
    return {"ok": True, "chunks": len(CHUNKS)}



@app.post("/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    await ensure_index()

    # ‡∏Å‡∏±‡∏ô‡πÄ‡∏Ñ‡∏™‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏á
    text_q = (req.message or "").strip()
    if not text_q:
        return ChatResponse(
            reply="‡πÇ‡∏õ‡∏£‡∏î‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (‡πÄ‡∏ä‡πà‡∏ô: ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£, ‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£, ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà)",
            sources=[]
        )

    # 1) ‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å PROFILE ‡∏Å‡πà‡∏≠‡∏ô (‡∏ä‡∏∑‡πà‡∏≠/‡∏≠‡∏µ‡πÄ‡∏°‡∏•/‡πÄ‡∏ö‡∏≠‡∏£‡πå/‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Ø‡∏•‡∏Ø)
    direct = answer_from_profile(text_q)
    if direct:
        return ChatResponse(reply=direct, sources=[])

    # 2) ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ/‡∏õ‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡∏¥‡∏î ‚Üí summarize ‡∏à‡∏≤‡∏Å PDF
    if is_summary_query(text_q):
        reply = summarize_all_chunks(CHUNKS)
        return ChatResponse(reply=reply, sources=[])

    # 3) Retrieval ‡∏õ‡∏Å‡∏ï‡∏¥ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ retrieve_hybrid ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡πà‡∏≠‡∏ô)
    q_norm = normalize_query(text_q)
    try:
        hits = retrieve_hybrid(q_norm, k=5, alpha=0.6)  # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ
        # hits: [(idx, chunk, score), ...]
        contexts = [h[1] for h in hits[:3] if len(h) >= 2]
        previews = [(h[0], (h[1][:140] + ("..." if len(h[1]) > 140 else ""))) for h in hits[:3] if len(h) >= 2]
    except NameError:
        hits = retrieve(q_norm, k=5)  # ‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏î‡∏¥‡∏°
        # hits: [(idx, chunk), ...]
        contexts = [c for _, c in hits[:3]]
        previews = [(i, (c[:140] + ("..." if len(c) > 140 else ""))) for i, c in hits[:3]]

    if contexts:
        reply = ask_gemini(text_q, contexts)
        # ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô Opinion (‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏∂‡∏î PDF) ‚Üí ‡πÄ‡∏ï‡∏¥‡∏°‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏£‡∏¥‡∏á
        if reply.startswith("‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Opinion):"):
            reply += "\n\n" + opinion_footer()
    else:
        # ‚ùó ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡πá‡∏Å‡∏ã‡πå‡∏à‡∏≤‡∏Å PDF
        if ALLOW_OPINION:
            reply = ask_opinion(text_q)
            reply += "\n\n" + opinion_footer()
        else:
            reply = "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PDF"

    return ChatResponse(reply=reply, sources=previews)

